# Malware-clase-2
Construyendo un clasificador para identificar archivos ejecutables maliciosos

Datos importantes de la base
•	Tamaño: 373 muestras (301 maliciosas, 72 benignas)
•	Desbalance: Prevalencia de muestras maliciosas
•	Características: 531 características representadas como F_1 a F_531
•	Etiqueta: Columna indicando si el archivo es malicioso o no (true para malware)
•	Nota: Las características binarias se representan numéricamente por simplicidad (F_1, F_2, etc.)

Cargar datos:
Abrir la base de datos Malware detection y se visualizar los primeros datos de la base

# 1. Preparación del dataset:
La visión general inicial del dataset nos permite mostrando las primeras filas, información sobre los tipos de datos y características, estadísticas 
descriptivas y el conteo de muestras por etiqueta. Esto nos ayudará a entender mejor la estructura de los datos y comenzar a identificar posibles desafíos, 
 como desbalance de clases o características faltantes.
 
Preprocesa el dataset para manejar valores nulos o inconsistentes:

Manejo de valores nulos: usar la imputación para rellenar los valores nulos. Se usar la media o la mediana de cada característica para reemplazar los valores 
nulos.

Aplica técnicas de reducción de dimensionalidad:

Una de las aplicaciones de PCA es la reducción de dimensionalidad (variables), perdiendo la menor cantidad de información (varianza) posible: cuando
contamos con un gran número de variables cuantitativas posiblemente correlacionadas (indicativo de existencia de información redundante), PCA permite
reducirlas a un número menor de variables transformadas (componentes principales) que expliquen gran parte de la variabilidad en los datos. 
Este código aplica PCA para reducir la dimensionalidad de los datos a 100 componentes principales y devuelve el conjunto de datos transformado en función de
estos componentes.

# 2. Selección de técnicas de aprendizaje automático
Random Forest :  es un algoritmo de conjunto que combina múltiples árboles de decisión para realizar la clasificación. Es robusto, puede manejar grandes
conjuntos de datos y es menos propenso al sobreajuste.

Gradient Boosting: es una técnica de aprendizaje automático que se utiliza para resolver problemas de regresión y clasificación, construye un modelo
predictivo fuerte combinando múltiples modelos de aprendizaje débil, como árboles de decisión poco profundos, de manera secuencial.


# 3. Entrenamiento del modelo
Implementa las técnicas de aprendizaje automático elegidas:

Inicialización del modelo Random Forest, se define la cuadrícula de hiperparámetros a ajustar y se inicialización de GridSearchCV para búsqueda de hiperparámetros

Lo que hemos realizado es definir una cuadrícula de hiperparámetros que queremos ajustar utilizando GridSearchCV. Este método realiza una búsqueda
exhaustiva sobre una cuadrícula de valores de hiperparámetros dados y evalúa el rendimiento del modelo utilizando la validación cruzada. Una vez que
GridSearchCV ha encontrado los mejores hiperparámetros, los utilizamos para entrenar el modelo en todo el conjunto de entrenamiento. 

Entrena el modelo utilizando el conjunto de entrenamiento:
Se corre el modelo, se pptimiza los hiperparámetros del modelo para obtener la mejor precisión posible, considerando el desbalance de clases y se mejora precisión obtenida durante la búsqueda de hiperparámetros dando como resultado durante la búsqueda de hiperparámetros un aproximadamente 0.996.

# 4.	Evaluación del modelo
Se evalúa el rendimiento del modelo en los conjuntos de validación y prueba, como resultado dio un rendimiento muy bueno tanto en el conjunto de validación como en el conjunto de prueba. Esto implica que el modelo es capaz de clasificar todas las muestras correctamente y  sugieren que el modelo ha aprendido muy bien los patrones distintivos entre las clases "malicious" y "non-malicious" en los datos y es muy efectivo para hacer predicciones precisas

# 5.	Interpretación del modelo
Los resultados muestran que el modelo Random Forest se ha entrenado y generalizado muy bien a los datos de validación y prueba. No hay evidencia de sobreajuste (overfitting) y el modelo es capaz de clasificar correctamente con una precisión del 100%

La matriz de confusion nos permitio ver los resultados que presenta el modelo, como los siguientes:
Verdaderos positivos (TP): El modelo predijo correctamente 61 muestras como maliciosas (malware).
Falsos negativos (FN): No hubo falsos negativos, lo que significa que el modelo no clasificó incorrectamente ninguna muestra de malware como benigna.
Falsos positivos (FP): No hubo falsos positivos, lo que indica que el modelo no clasificó incorrectamente ninguna muestra benigna como malware.
Verdaderos negativos (TN): El modelo predijo correctamente 14 muestras como benignas.

En resumen, el modelo no cometió errores en la clasificación de las muestras en el conjunto de prueba. Todos los resultados de la clasificación fueron
correctos, lo que sugiere que el modelo tiene un rendimiento excelente en la detección de malware.

